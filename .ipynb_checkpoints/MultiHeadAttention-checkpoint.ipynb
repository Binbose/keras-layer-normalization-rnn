{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPool2D, Flatten, Multiply, Permute, Embedding, LSTM, Bidirectional, Merge\n",
    "from keras.preprocessing import sequence\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_as_words(word_to_id, index_from, sentence_as_token):\n",
    "    INDEX_FROM=3   # word index offset\n",
    "\n",
    "    \n",
    "    word_to_id = {k:(v+INDEX_FROM) for k,v in word_to_id.items()}\n",
    "    word_to_id[\"<PAD>\"] = 0\n",
    "    word_to_id[\"<START>\"] = 1\n",
    "    word_to_id[\"<UNK>\"] = 2\n",
    "\n",
    "    id_to_word = {value:key for key,value in word_to_id.items()}\n",
    "    sentence = ' '.join(id_to_word[id] for id in sentence_as_token )\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (25000, 80)\n",
      "x_test shape: (25000, 80)\n"
     ]
    }
   ],
   "source": [
    "max_features = 20000\n",
    "maxlen = 80  # cut texts after this number of words (among top max_features most common words)\n",
    "batch_size = 32\n",
    "INDEX_FROM = 3\n",
    "\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features, index_from = INDEX_FROM)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(Layer):\n",
    "    # Implemented like in \"Attention is all you need\"  \n",
    "    # https://arxiv.org/pdf/1706.03762.pdf\n",
    "    def __init__(self, output_dim, use_key_value_predict = True, return_sequence=True, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        self.use_key_value_predict = use_key_value_predict\n",
    "        self.return_sequence = return_sequence\n",
    "        super(ScaledDotProductAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.input_shape_ = input_shape\n",
    "        \n",
    "        if self.use_key_value_predict:\n",
    "            self.predict_size = self.output_dim\n",
    "            if (input_shape[-1] - self.predict_size)%2 != 0:\n",
    "                assert(\"When using key_value_predict scheme, input_dim - output_dim must be divisible by 2.\")\n",
    "            self.key_value_size = (input_shape[-1] - self.predict_size)//2\n",
    "        else:\n",
    "            self.key_value_size = self.predict_size = input_shape[-1]\n",
    "        \n",
    "        self.W_k = self.add_weight(name=\"W_k\", shape=(self.key_value_size, self.output_dim), initializer='uniform', trainable=True)\n",
    "        self.W_v = self.add_weight(name=\"W_v\", shape=(self.key_value_size, self.output_dim), initializer='uniform', trainable=True)\n",
    "        self.W_p = self.add_weight(name=\"W_p\", shape=(self.predict_size, self.output_dim), initializer='uniform', trainable=True)\n",
    "\n",
    "        \n",
    "        super(ScaledDotProductAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, x): \n",
    "        x.set_shape(self.input_shape_)\n",
    "        \n",
    "        if self.use_key_value_predict:\n",
    "            key = x[..., :self.key_value_size]\n",
    "            value = x[..., self.key_value_size:2*self.key_value_size]\n",
    "            predict = x[..., 2*self.key_value_size:]\n",
    "        else:\n",
    "            key = value = predict = x\n",
    "        \n",
    "        \n",
    "        ai = K.dot(key, self.W_k)\n",
    "        aj = K.permute_dimensions( K.dot(value, self.W_v), (0, 2, 1) )\n",
    "        e = K.batch_dot ( ai, aj) / np.sqrt(self.output_dim) \n",
    "        \n",
    "        self.attention_weights = K.softmax( e, axis=2 )\n",
    "        \n",
    "        v = K.dot( predict, self.W_p )\n",
    "        context_vector = K.batch_dot( self.attention_weights, v)\n",
    "        \n",
    "        if self.return_sequence == False:\n",
    "            context_vector  = K.sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        print(input_shape)\n",
    "        if self.return_sequence:\n",
    "            return (input_shape[0], input_shape[1], self.output_dim)\n",
    "        else:\n",
    "            return (input_shape[0], self.output_dim)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "class MultiHeadScaledDotProductAttention(Layer):\n",
    "    # Implemented like in \"Attention is all you need\"  \n",
    "    # https://arxiv.org/pdf/1706.03762.pdf\n",
    "    def __init__(self, n_heads, output_dim, use_key_value_predict = True, return_sequence=True, **kwargs):\n",
    "        self.n_heads = n_heads\n",
    "        self.output_dim = output_dim\n",
    "        self.use_key_value_predict = use_key_value_predict\n",
    "        self.return_sequence = return_sequence\n",
    "        super(MultiHeadScaledDotProductAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.input_shape_ = input_shape\n",
    "        \n",
    "        if self.use_key_value_predict:\n",
    "            self.predict_size = self.output_dim\n",
    "            if (input_shape[-1] - self.predict_size)%2 != 0:\n",
    "                assert(\"When using key_value_predict scheme, input_dim - output_dim must be divisible by 2.\")\n",
    "            self.key_value_size = (input_shape[-1] - self.predict_size)//2\n",
    "        else:\n",
    "            self.key_value_size = self.predict_size = input_shape[-1]\n",
    "        \n",
    "        self.W_k = self.add_weight(name=\"W_k\", shape=(self.n_heads, self.key_value_size, self.output_dim), initializer='uniform', trainable=True)\n",
    "        self.W_v = self.add_weight(name=\"W_v\", shape=(self.n_heads, self.key_value_size, self.output_dim), initializer='uniform', trainable=True)\n",
    "        self.W_p = self.add_weight(name=\"W_p\", shape=(self.n_heads, self.predict_size, self.output_dim), initializer='uniform', trainable=True)\n",
    "\n",
    "        \n",
    "        super(MultiHeadScaledDotProductAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, x): \n",
    "        x.set_shape(self.input_shape_)\n",
    "        \n",
    "        if self.use_key_value_predict:\n",
    "            key = x[..., :self.key_value_size]\n",
    "            value = x[..., self.key_value_size:2*self.key_value_size]\n",
    "            predict = x[..., 2*self.key_value_size:]\n",
    "        else:\n",
    "            key = value = predict = x\n",
    "        \n",
    "        \n",
    "        ai = K.dot(key, self.W_k)\n",
    "        ai = K.permute_dimensions(ai, (0, 2, 1, 3))\n",
    "        \n",
    "       \n",
    "        aj = K.dot(value, self.W_v)\n",
    "        aj = K.permute_dimensions( aj,(0, 2, 3, 1) )\n",
    "        \n",
    "        e = K.batch_dot ( ai, aj) / np.sqrt(self.output_dim) \n",
    "        \n",
    "        self.attention_weights = K.softmax( e, axis=3 )\n",
    "        \n",
    "        v = K.dot( predict, self.W_p )\n",
    "        v = K.permute_dimensions(v, (0, 2, 1, 3))\n",
    "        context_vector = K.batch_dot( self.attention_weights, v)\n",
    "        \n",
    "        context_vector = K.reshape(context_vector, (-1, self.input_shape_[1], self.n_heads*self.output_dim))\n",
    "\n",
    "        return context_vector\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.return_sequence:\n",
    "            return (input_shape[0], input_shape[1], self.output_dim * self.n_heads)\n",
    "        else:\n",
    "            return (input_shape[0], self.output_dim * self.n_heads)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleAdditiveSelfAttention(Layer):\n",
    "    # Implemented like in \"Hierarchical Attention Networks for Document Classification\"  \n",
    "    # http://www.cs.cmu.edu/~./hovy/papers/16HLT-hierarchical-attention-networks.pdf\n",
    "    def __init__(self, alignment_vector_size, window_size = None, return_sequence=False, mode=\"add\", **kwargs):\n",
    "        self.alignment_vector_size = alignment_vector_size\n",
    "        self.return_sequence = return_sequence\n",
    "        self.window_size = window_size\n",
    "        self.mode = mode\n",
    "        super(SimpleAdditiveSelfAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.input_shape_ = input_shape\n",
    "\n",
    "        self.alignment_vector = self.add_weight(name=\"alignment_vector\", shape=(self.alignment_vector_size,), initializer='uniform', trainable=True)\n",
    "        self.kernel = self.add_weight(name=\"kernel\", shape=(self.alignment_vector_size, input_shape[2]), initializer='uniform', trainable=True)\n",
    "        self.bias = self.add_weight(name=\"bias\", shape=(self.alignment_vector_size,), initializer='uniform', trainable=True)\n",
    "        \n",
    "        super(SimpleAdditiveSelfAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, hidden_state_sequence): \n",
    "        hidden_state_sequence.set_shape(self.input_shape_)\n",
    "        \n",
    "        if self.window_size is not None and self.input_shape_[1] > self.window_size:\n",
    "            hidden_state_sequence = hidden_state_sequence[:, -self.window_size:]\n",
    "        \n",
    "        \n",
    "        u = K.tanh( K.squeeze(K.dot(hidden_state_sequence, K.expand_dims(self.kernel)), axis=-1) + self.bias )\n",
    "        print(u.shape)\n",
    "        \n",
    "        aligned_u = K.squeeze(K.dot(u, K.expand_dims(self.alignment_vector)), axis=-1)\n",
    "        print(aligned_u.shape)\n",
    "        self.attention_weights = K.softmax( aligned_u, axis=1 )\n",
    "        print(self.attention_weights.shape)\n",
    "        \n",
    "        if self.return_sequence:\n",
    "            context_vector = K.expand_dims(self.attention_weights,axis=2) * hidden_state_sequence\n",
    "        else:\n",
    "            context_vector = K.sum( K.expand_dims(self.attention_weights,axis=2) * hidden_state_sequence, axis=1 )\n",
    "\n",
    "        return context_vector\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.return_sequence:\n",
    "            if self.window_size is not None and self.input_shape_[1] > self.window_size:\n",
    "                return (input_shape[0], self.window_size, input_shape[2])\n",
    "                \n",
    "            return input_shape\n",
    "        else:\n",
    "            return (input_shape[0], input_shape[2])\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "class MultiHeadAdditiveSelfAttention(Layer):\n",
    "    # Implemented like in \"Hierarchical Attention Networks for Document Classification\"  \n",
    "    # http://www.cs.cmu.edu/~./hovy/papers/16HLT-hierarchical-attention-networks.pdf\n",
    "    def __init__(self, n_heads, alignment_vector_size, window_size = None, return_sequence=False, mode=\"add\", **kwargs):\n",
    "        self.n_heads = n_heads\n",
    "        self.alignment_vector_size = alignment_vector_size\n",
    "        self.return_sequence = return_sequence\n",
    "        self.window_size = window_size\n",
    "        self.mode = mode\n",
    "        super(MultiHeadAdditiveSelfAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.input_shape_ = input_shape\n",
    "\n",
    "        self.alignment_vector = self.add_weight(name=\"alignment_vector\", shape=(self.n_heads, self.alignment_vector_size,), initializer='uniform', trainable=True)\n",
    "        self.kernel = self.add_weight(name=\"kernel\", shape=(self.alignment_vector_size, input_shape[2]), initializer='uniform', trainable=True)\n",
    "        self.bias = self.add_weight(name=\"bias\", shape=(self.alignment_vector_size,), initializer='uniform', trainable=True)\n",
    "        self.attention_weights = self.add_weight(name=\"attention_weights\", shape=(self.n_heads, input_shape[1]), initializer='uniform', trainable=False)\n",
    "        \n",
    "        super(MultiHeadAdditiveSelfAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, hidden_state_sequence): \n",
    "        hidden_state_sequence.set_shape(self.input_shape_)\n",
    "        \n",
    "        if self.window_size is not None and self.input_shape_[1] > self.window_size:\n",
    "            hidden_state_sequence = hidden_state_sequence[:, -self.window_size:]\n",
    "        \n",
    "        u = K.tanh( K.squeeze(K.dot(hidden_state_sequence, K.expand_dims(self.kernel)), axis=-1) + self.bias )\n",
    "       \n",
    "        score = K.squeeze(K.dot(u, K.expand_dims(self.alignment_vector)), axis=-1)\n",
    "        self.attention_weights = K.softmax( score, axis=1 )\n",
    "        self.attention_weights = K.permute_dimensions(self.attention_weights, (0,2,1))\n",
    "\n",
    "        \n",
    "        if self.return_sequence:\n",
    "            print(K.expand_dims(self.attention_weights,axis=3).shape)\n",
    "            print(hidden_state_sequence.shape)\n",
    "            context_vector = K.expand_dims(self.attention_weights, axis=3)* hidden_state_sequence\n",
    "            print(context_vector.shape)\n",
    "            context_vector = K.permute_dimensions(context_vector, (0,2,1,3))\n",
    "            context_vector = K.reshape(context_vector, (-1, context_vector.shape[1], context_vector.shape[2]*context_vector.shape[3]))\n",
    "        else:\n",
    "            context_vector = K.batch_dot(self.attention_weights, hidden_state_sequence)\n",
    "            context_vector = K.reshape(context_vector, (-1, context_vector.shape[1]*context_vector.shape[2]))\n",
    "            \n",
    "        return context_vector\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.return_sequence:\n",
    "            if self.window_size is not None and self.input_shape_[1] > self.window_size:\n",
    "                return (input_shape[0], self.window_size, input_shape[2])\n",
    "                \n",
    "            \n",
    "            return (input_shape[0], input_shape[1], input_shape[2]*self.n_heads)\n",
    "        else:\n",
    "            return (input_shape[0], input_shape[2]*self.n_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.get_session().close()\n",
    "cfg = K.tf.ConfigProto()\n",
    "cfg.gpu_options.allow_growth = True\n",
    "K.set_session(K.tf.Session(config=cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 8, 80, 1)\n",
      "(?, 80, 256)\n",
      "(?, 8, 80, 256)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_98 (InputLayer)        (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "embedding_98 (Embedding)     (None, 80, 128)           2560000   \n",
      "_________________________________________________________________\n",
      "bidirectional_112 (Bidirecti (None, 80, 256)           263168    \n",
      "_________________________________________________________________\n",
      "Attention (MultiHeadAdditive (None, 80, 2048)          3290      \n",
      "_________________________________________________________________\n",
      "bidirectional_113 (Bidirecti (None, 256)               2229248   \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 5,055,963\n",
      "Trainable params: 5,055,323\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(maxlen,))\n",
    "x = Embedding(max_features, 128)(inputs)\n",
    "\n",
    "x = Bidirectional(LSTM(128, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))(x)\n",
    "#x = ScaledDotProductAttention(10, return_sequence=False)(x)\n",
    "x = MultiHeadAdditiveSelfAttention(8, 10, return_sequence=True, name=\"Attention\")(x)\n",
    "x = Bidirectional(LSTM(128, dropout=0.2, recurrent_dropout=0.2))(x)\n",
    "\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/6\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [32,8,80,1] vs. [32,80,256]\n\t [[Node: Attention_85/mul = Mul[T=DT_FLOAT, _class=[\"loc:@training_14/RMSprop/gradients/AddN_23\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Attention_85/ExpandDims_3, bidirectional_112/concat)]]\n\t [[Node: metrics_28/acc/Mean_1/_1241 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_7813_metrics_28/acc/Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'Attention_85/mul', defined at:\n  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-267-95c219d983f6>\", line 6, in <module>\n    x = MultiHeadAdditiveSelfAttention(8, 10, return_sequence=True, name=\"Attention\")(x)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py\", line 619, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"<ipython-input-264-34a6413646ed>\", line 91, in call\n    context_vector = K.expand_dims(self.attention_weights, axis=3)* hidden_state_sequence\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 979, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1211, in _mul_dispatch\n    return gen_math_ops.mul(x, y, name=name)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 5066, in mul\n    \"Mul\", x=x, y=y, name=name)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Incompatible shapes: [32,8,80,1] vs. [32,80,256]\n\t [[Node: Attention_85/mul = Mul[T=DT_FLOAT, _class=[\"loc:@training_14/RMSprop/gradients/AddN_23\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Attention_85/ExpandDims_3, bidirectional_112/concat)]]\n\t [[Node: metrics_28/acc/Mean_1/_1241 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_7813_metrics_28/acc/Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [32,8,80,1] vs. [32,80,256]\n\t [[Node: Attention_85/mul = Mul[T=DT_FLOAT, _class=[\"loc:@training_14/RMSprop/gradients/AddN_23\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Attention_85/ExpandDims_3, bidirectional_112/concat)]]\n\t [[Node: metrics_28/acc/Mean_1/_1241 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_7813_metrics_28/acc/Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-268-96d01a665879>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1236\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1237\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2482\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2483\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1334\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1335\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1337\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [32,8,80,1] vs. [32,80,256]\n\t [[Node: Attention_85/mul = Mul[T=DT_FLOAT, _class=[\"loc:@training_14/RMSprop/gradients/AddN_23\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Attention_85/ExpandDims_3, bidirectional_112/concat)]]\n\t [[Node: metrics_28/acc/Mean_1/_1241 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_7813_metrics_28/acc/Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'Attention_85/mul', defined at:\n  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-267-95c219d983f6>\", line 6, in <module>\n    x = MultiHeadAdditiveSelfAttention(8, 10, return_sequence=True, name=\"Attention\")(x)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py\", line 619, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"<ipython-input-264-34a6413646ed>\", line 91, in call\n    context_vector = K.expand_dims(self.attention_weights, axis=3)* hidden_state_sequence\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 979, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1211, in _mul_dispatch\n    return gen_math_ops.mul(x, y, name=name)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 5066, in mul\n    \"Mul\", x=x, y=y, name=name)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Incompatible shapes: [32,8,80,1] vs. [32,80,256]\n\t [[Node: Attention_85/mul = Mul[T=DT_FLOAT, _class=[\"loc:@training_14/RMSprop/gradients/AddN_23\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Attention_85/ExpandDims_3, bidirectional_112/concat)]]\n\t [[Node: metrics_28/acc/Mean_1/_1241 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_7813_metrics_28/acc/Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=6, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpret model attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "that played the <UNK> of norman and paul they were just brilliant children are often left out of the praising list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n"
     ]
    }
   ],
   "source": [
    "word_to_id = keras.datasets.imdb.get_word_index()\n",
    "sentence = get_sentence_as_words(word_to_id, INDEX_FROM, x_train[0])\n",
    "print(sentence)\n",
    "\n",
    "sentence = sentence.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b635475cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attention_weights = get_attention_weights(model, \"Attention\", x_train[0])[0]\n",
    "ind = range(attention_weights.shape[0])\n",
    "plt.bar(ind, attention_weights)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['were', 'just', 'brilliant', 'children']\n",
      "brilliant\n",
      "['children', 'are', 'amazing', 'and']\n",
      "amazing\n",
      "[\"someone's\", 'life', 'after', 'all', 'that', 'was', 'shared', 'with', 'us', 'all']\n"
     ]
    }
   ],
   "source": [
    "print(sentence[9:13])\n",
    "print(sentence[11])\n",
    "\n",
    "print(sentence[43:47])\n",
    "print(sentence[45])\n",
    "\n",
    "print(sentence[70:80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
